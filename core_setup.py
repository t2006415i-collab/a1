import io
import json
import base64
import logging
import copy
import os
import time
import threading
from datetime import datetime
from urllib.parse import quote

from flask import Flask, request, jsonify, make_response, send_from_directory
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from pypdf import PdfReader, PdfWriter

import arabic_reshaper
from bidi.algorithm import get_display
from ftplib import FTP, all_errors as FTP_ALL_ERRORS

# --- Configuration Constants ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | %(threadName)s | %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

FONT_REGISTERED = False
REGISTERED_FONT_NAME = "CustomArabic"

OUTPUT_FOLDER = "output_jobs"
PAGES_PER_PART = 4 # Default value, now configurable
JOBS_DATA_FILE = "jobs_data.json"

MAX_RETRY = 3 # New: Maximum number of print retries

# --- Global Data Structures and Locks ---
PRINT_JOBS = [] # Master list of all jobs
CONTINUOUS_QUEUE = [] # Queue of job IDs for continuous printing (Producer-Consumer Queue)
QUEUE_LOCK = threading.Lock()
WORKER_THREAD = None # Reference to the persistent worker thread
WORKER_STOP_EVENT = threading.Event() # Event to signal the worker to stop

# --- Persistence Functions ---

def save_jobs_to_file():
    """Saves the PRINT_JOBS list to a JSON file in a thread-safe manner."""
    # NOTE: This function is expected to be called *while* holding the QUEUE_LOCK.
    try:
        # Use a temporary file for atomic write
        temp_path = JOBS_DATA_FILE + ".tmp"
        with open(temp_path, 'w', encoding='utf-8') as f:
            json.dump(PRINT_JOBS, f, ensure_ascii=False, indent=4)
        os.replace(temp_path, JOBS_DATA_FILE)
        logging.info(f"âœ… ØªÙ… Ø­ÙØ¸ {len(PRINT_JOBS)} ÙˆØ¸ÙŠÙØ© Ø·Ø¨Ø§Ø¹Ø© Ø¥Ù„Ù‰ {JOBS_DATA_FILE}.")
    except Exception as e:
        logging.error(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© Ø¥Ù„Ù‰ {JOBS_DATA_FILE}: {e}", exc_info=True)

def load_jobs_from_file():
    """Loads the PRINT_JOBS list from a JSON file in a thread-safe manner."""
    global PRINT_JOBS
    if not os.path.exists(JOBS_DATA_FILE):
        logging.info(f"â„¹ï¸ Ù…Ù„Ù {JOBS_DATA_FILE} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø¨Ø¯Ø¡ Ø¨Ù‚Ø§Ø¦Ù…Ø© ÙˆØ¸Ø§Ø¦Ù ÙØ§Ø±ØºØ©.")
        return

    with QUEUE_LOCK:
        try:
            with open(JOBS_DATA_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, list):
                    # Ensure new fields exist for compatibility/robustness
                    for job in data:
                        job.setdefault('retry_count', 0)
                        # Revert 'Printing' status to 'Ready' on startup crash recovery
                        if job['status'] == 'Printing':
                            job['status'] = 'Ready'
                            logging.warning(f"âš ï¸ ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø­Ø§Ù„Ø© Ø§Ù„ÙˆØ¸ÙŠÙØ© {job['id']} Ù…Ù† 'Printing' Ø¥Ù„Ù‰ 'Ready' Ø¨Ø¹Ø¯ ØªØ¹Ø·Ù„ Ø§Ù„Ø®Ø§Ø¯Ù….")

                    PRINT_JOBS = data
                    logging.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(PRINT_JOBS)} ÙˆØ¸ÙŠÙØ© Ø·Ø¨Ø§Ø¹Ø© Ù…Ù† {JOBS_DATA_FILE}.")
                else:
                    logging.error(f"âŒ Ù…Ø­ØªÙˆÙ‰ {JOBS_DATA_FILE} ØºÙŠØ± ØµØ§Ù„Ø­ (Ù„ÙŠØ³ Ù‚Ø§Ø¦Ù…Ø©). Ø¨Ø¯Ø¡ Ø¨Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ©.")
                    PRINT_JOBS = []
        except json.JSONDecodeError as e:
            logging.error(f"âŒ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ JSON ÙÙŠ {JOBS_DATA_FILE}: {e}. Ø¨Ø¯Ø¡ Ø¨Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ©.", exc_info=True)
            PRINT_JOBS = []
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ {JOBS_DATA_FILE}: {e}. Ø¨Ø¯Ø¡ Ø¨Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ©.", exc_info=True)
            PRINT_JOBS = []

# --- Persistent Worker Thread Implementation (New Architecture) ---

def print_queue_worker():
    """
    Dedicated persistent worker thread for continuous printing (Consumer).
    It ensures continuous operation and manages job retries and flow control.
    """
    global CONTINUOUS_QUEUE
    while not WORKER_STOP_EVENT.is_set():
        job_id = None
        
        with QUEUE_LOCK:
            if CONTINUOUS_QUEUE:
                # Pop the next job ID from the front of the queue
                job_id = CONTINUOUS_QUEUE.pop(0)
            
        if job_id:
            logging.info(f"ğŸ”„ Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„Ù…Ø³ØªÙ…Ø±: Ø³Ø­Ø¨ Ù…Ù‡Ù…Ø© Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© ID: {job_id} Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±.")
            
            # Retrieve the full job data
            job_found = next((job for job in PRINT_JOBS if job['id'] == job_id), None)
            
            if not job_found:
                logging.error(f"âŒ Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„Ù…Ø³ØªÙ…Ø±: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙØ© ID: {job_id} ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©. ØªØ®Ø·ÙŠ.")
                continue

            # Check if the job is already being printed (Concurrency Guard)
            if job_found['status'] == 'Printing':
                logging.warning(f"âš ï¸ Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„Ù…Ø³ØªÙ…Ø±: Ø§Ù„ÙˆØ¸ÙŠÙØ© ID: {job_id} ØªÙ… ÙˆØ¶Ø¹ Ø¹Ù„Ø§Ù…Ø© Ø¹Ù„ÙŠÙ‡Ø§ Ø¨Ø§Ù„ÙØ¹Ù„ 'Printing'. ØªØ®Ø·ÙŠ (Ù‚Ø¯ ØªÙƒÙˆÙ† Ù‚ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¨Ø§Ù„ÙØ¹Ù„ ÙÙŠ Ù…ÙˆØ¶ÙˆØ¹ Ø¢Ø®Ø±).")
                continue

            # Start the print job in a new non-recursive thread
            thread_name = f"FTP_Continuous_Print_{job_id}"
            ftp_thread = threading.Thread(
                target=print_job_ftp,
                args=(job_id, 
                      job_found.get('printer_ip'),
                      job_found.get('ftp_user'),
                      job_found.get('ftp_pwd', ''),
                      job_found.get('ring_number'),
                      True # is_continuous flag remains True for worker-initiated jobs
                      ),
                name=thread_name
            )
            ftp_thread.start()
        
        # Sleep for a few seconds to avoid tight loop CPU spin
        time.sleep(3)

def start_worker_thread():
    """Starts the persistent print queue worker thread."""
    global WORKER_THREAD
    if WORKER_THREAD is None or not WORKER_THREAD.is_alive():
        WORKER_THREAD = threading.Thread(target=print_queue_worker, name="PrintQueueWorker")
        WORKER_THREAD.daemon = True # Allow main thread to exit even if worker is running
        WORKER_THREAD.start()
        logging.info("ğŸš€ Ø¨Ø¯Ø£ ØªØ´ØºÙŠÙ„ Ø®ÙŠØ· Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„Ù…Ø³ØªÙ…Ø± (PrintQueueWorker) Ø¨Ù†Ø¬Ø§Ø­.")
    else:
        logging.info("â„¹ï¸ Ø®ÙŠØ· Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„Ù…Ø³ØªÙ…Ø± Ù‚ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¨Ø§Ù„ÙØ¹Ù„.")

# --- Utility Functions (Unchanged) ---

def register_custom_font(font_data: bytes) -> bool:
    global FONT_REGISTERED, REGISTERED_FONT_NAME
    if FONT_REGISTERED:
        return True
    try:
        font_stream = io.BytesIO(font_data)
        pdfmetrics.registerFont(TTFont(REGISTERED_FONT_NAME, font_stream))
        pdfmetrics.registerFontFamily(REGISTERED_FONT_NAME, normal=REGISTERED_FONT_NAME)
        FONT_REGISTERED = True
        logging.info("âœ… ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø· Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø¨Ù†Ø¬Ø§Ø­.")
        return True
    except Exception as e:
        logging.error("âŒ ÙØ´Ù„ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø·: %s", e, exc_info=True)
        FONT_REGISTERED = False
        return False

def process_arabic_text(text: str) -> str:
    if not text or not text.strip():
        return ''
    try:
        reshaped_text = arabic_reshaper.reshape(text)
        bidi_text = get_display(reshaped_text)
        return bidi_text
    except Exception as e:
        logging.error("Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ '%s': %s", text[:20], e)
        return text

def create_watermark(name: str, student_id: str, config: dict, font_data: bytes) -> io.BytesIO:
    font_available = register_custom_font(font_data)
    font_name = REGISTERED_FONT_NAME if font_available else 'Helvetica-Bold'
    font_size = 12
    packet = io.BytesIO()
    can = canvas.Canvas(packet, pagesize=A4)
    
    processed_name = process_arabic_text(name)
    processed_id = str(student_id)

    name_x = float(config.get('name_x', 375))
    name_y = float(config.get('name_y', 452.5))
    id_x = float(config.get('id_x', 400))
    id_y = float(config.get('id_y', 422.5))

    can.setFont(font_name, font_size)
    can.setFillColorRGB(0, 0, 0)
    can.drawRightString(name_x, name_y, processed_name)

    can.setFont(font_name, font_size)
    can.drawString(id_x, id_y, processed_id) 
    
    can.save()
    packet.seek(0)
    return packet

def split_pdf_ranges(job_id: str, pdf_data: io.BytesIO, pages_per_part: int) -> int:
    try:
        reader = PdfReader(pdf_data)
        total_pages = len(reader.pages)
        part_count = 0
        
        full_filename = f"{job_id}_FULL.pdf"
        # Ensure OUTPUT_FOLDER exists
        if not os.path.exists(OUTPUT_FOLDER):
            os.makedirs(OUTPUT_FOLDER)
        
        with open(os.path.join(OUTPUT_FOLDER, full_filename), "wb") as f:
            pdf_data.seek(0)
            f.write(pdf_data.read())

        for i in range(0, total_pages, pages_per_part):
            writer = PdfWriter()
            end_page = min(i + pages_per_part, total_pages)
            for page_num in range(i, end_page):
                writer.add_page(reader.pages[page_num])
            
            part_count += 1
            part_filename = f"{job_id}_P{part_count:03}.pdf"
            with open(os.path.join(OUTPUT_FOLDER, part_filename), "wb") as f:
                writer.write(f)

        logging.info(f"âœ… ØªÙ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ù‡Ù…Ø© {job_id} Ø¥Ù„Ù‰ {part_count} Ø¬Ø²Ø¡.")
        return part_count

    except Exception as e:
        logging.error("âŒ ÙØ´Ù„ ØªÙ‚Ø³ÙŠÙ… Ù…Ù„Ù PDF: %s", e, exc_info=True)
        return 0

# --- Core Printing Function (Modified) ---

def print_job_ftp(job_id: str, printer_ip: str, ftp_user: str, ftp_pwd: str, ring_number: str, is_continuous: bool = False):
    
    # 1. Retrieve and Validate Job State
    with QUEUE_LOCK:
        job_found = next((job for job in PRINT_JOBS if job['id'] == job_id), None)
        if not job_found:
            logging.error(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¸ÙŠÙØ© ID: {job_id} Ù„Ù„Ø¥Ø±Ø³Ø§Ù„.")
            return

        # 2. Update Status to Printing
        job_found['status'] = 'Printing'
        job_found['start_time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        save_jobs_to_file() # Persistence point B: Status change to Printing
        logging.info(f"ğŸ”„ Ø¨Ø¯Ø£ Ø¥Ø±Ø³Ø§Ù„ Ù…Ù‡Ù…Ø© Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© ID: {job_id} (Ù…Ø­Ø§ÙˆÙ„Ø©: {job_found['retry_count'] + 1}) Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø§Ø¨Ø¹Ø© {printer_ip} Ø¨Ø±Ù‚Ù… Ø±ÙŠÙ†Ø¬: {ring_number}")
    
    ftp = None
    success_count = 0
    job_successful = False
    
    # FIX: Initialize error_detail here to avoid Pylint E0601 error 
    # when accessing it in the 'finally' block if job_successful is False.
    error_detail = "ÙØ´Ù„ ØºÙŠØ± Ù…Ø­Ø¯Ø¯." 
    
    try:
        # 3. FTP Connection and File Transfer
        ftp = FTP(printer_ip, timeout=10)
        ftp.login(user=ftp_user, passwd=ftp_pwd)
        logging.info(f"âœ… ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù†Ø¬Ø§Ø­ Ø¨Ø§Ù„Ø·Ø§Ø¨Ø¹Ø© {printer_ip} Ø¹Ø¨Ø± FTP.")

        all_files = os.listdir(OUTPUT_FOLDER)
        job_files = sorted([f for f in all_files if f.startswith(f"{job_id}_P")])
        
        if not job_files:
            raise FileNotFoundError(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ø¬Ø²Ø¦ÙŠØ© Ù„Ù„ÙˆØ¸ÙŠÙØ© {job_id}.")

        for filename in job_files:
            local_path = os.path.join(OUTPUT_FOLDER, filename)
            
            # Konica Minolta Bizhub 287 stapling command:
            staple_tag = "_STAPLE"
            ftp_filename = f"{filename[:-4]}{staple_tag}_R{ring_number}.pdf"
            
            logging.info(f"   â¬†ï¸ Ø¬Ø§Ø±ÙŠ Ø¥Ø±Ø³Ø§Ù„: {filename} Ø¨Ø§Ø³Ù… {ftp_filename}...")
            
            with open(local_path, 'rb') as f:
                ftp.storbinary(f'STOR {ftp_filename}', f)
            
            success_count += 1
            logging.info(f"   âœ… ØªÙ… Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ø¨Ù†Ø¬Ø§Ø­.")
        
        job_successful = True # Set flag for successful print
        
    except FTP_ALL_ERRORS as e:
        # Log FTP Error
        logging.error(f"âŒ Ø®Ø·Ø£ FTP Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ Ù…Ù‡Ù…Ø© Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© ID: {job_id}: %s", e, exc_info=True)
        error_detail = f"Ø®Ø·Ø£ FTP: {e}"
    except FileNotFoundError as e:
        # Log File Error
        logging.error(f"âŒ Ø®Ø·Ø£ Ø§Ù„Ù…Ù„Ù Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ Ù…Ù‡Ù…Ø© Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© ID: {job_id}: %s", e, exc_info=True)
        error_detail = f"Ø®Ø·Ø£ Ø§Ù„Ù…Ù„Ù: {e}"
    except Exception as e:
        # Log General Error
        logging.error(f"âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ Ù…Ù‡Ù…Ø© Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© ID: {job_id}: %s", e, exc_info=True)
        error_detail = f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}"
        
    finally:
        # 4. Final Job Status Update and Retry Logic
        if ftp:
            try:
                ftp.quit()
            except FTP_ALL_ERRORS:
                pass

        with QUEUE_LOCK:
            job_found = next((job for job in PRINT_JOBS if job['id'] == job_id), None)
            if not job_found: # Should not happen, but for safety
                return 

            if job_successful:
                # Success Logic
                job_found['status'] = 'Printed'
                job_found['end_time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                job_found['print_details'] = f"ØªÙ… Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ø¨Ù†Ø¬Ø§Ø­ ({success_count} Ù…Ù„Ù) Ø¥Ù„Ù‰ {printer_ip} Ø¨Ø§Ù„Ø±ÙŠÙ†Ø¬ {ring_number}"
                logging.info(f"ğŸ‰ ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø¥Ø±Ø³Ø§Ù„ Ù…Ù‡Ù…Ø© Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© ID: {job_id}.")
            else:
                # Failure and Retry Logic
                job_found['end_time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                job_found['retry_count'] += 1
                job_found['print_details'] = error_detail # Usage is safe now
                
                if is_continuous and job_found['retry_count'] < MAX_RETRY:
                    # Reinsert at the start of the continuous queue for immediate retry
                    CONTINUOUS_QUEUE.insert(0, job_id)
                    job_found['status'] = 'Ready' # Set back to ready for the next attempt
                    logging.warning(f"ğŸ”„ ÙØ´Ù„ Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© ID: {job_id}. Ø¬Ø§Ø±ÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„ÙˆØ¸ÙŠÙØ© ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù„Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {job_found['retry_count'] + 1}/{MAX_RETRY}.")
                else:
                    # Final failure or manual print failure
                    job_found['status'] = 'Error'
                    logging.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ID: {job_id} Ø¨Ø¹Ø¯ {job_found['retry_count']} Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø£Ùˆ ÙØ´Ù„ Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ÙŠØ¯ÙˆÙŠØ©.")
            
            # 5. Save State
            save_jobs_to_file() # Persistence point C: Final status/retry update